{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengcao/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('./intermediate/train.csv') \n",
    "train_y = pd.read_csv('./intermediate/target.csv', header=-1)\n",
    "test_X = pd.read_csv('./intermediate/test.csv')\n",
    "ids = pd.read_csv('sample_submission.csv')['card_id']\n",
    "\n",
    "# for col in ['dayofweek', 'weekofyear', 'month', 'hist_first_buy']:\n",
    "# #     test_X[col].fillna(test_X[col].mode(), inplace=True)\n",
    "#     test_X[col].fillna(0, inplace=True)\n",
    "    \n",
    "# test_X['elapsed_time'].fillna(test_X['elapsed_time'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1                                0\n",
       "feature_2                                0\n",
       "feature_3                                0\n",
       "hist_month_nunique                       0\n",
       "hist_hour_nunique                        0\n",
       "hist_weekofyear_nunique                  0\n",
       "hist_dayofweek_nunique                   0\n",
       "hist_year_nunique                        0\n",
       "hist_subsector_id_nunique                0\n",
       "hist_merchant_id_nunique                 0\n",
       "hist_merchant_category_id_nunique        0\n",
       "hist_purchase_amount_sum                 0\n",
       "hist_purchase_amount_max                 0\n",
       "hist_purchase_amount_min                 0\n",
       "hist_purchase_amount_mean                0\n",
       "hist_purchase_amount_var                 0\n",
       "hist_installments_sum                    0\n",
       "hist_installments_max                    0\n",
       "hist_installments_min                    0\n",
       "hist_installments_mean                   0\n",
       "hist_installments_var                    0\n",
       "hist_purchase_date_max                   0\n",
       "hist_purchase_date_min                   0\n",
       "hist_month_lag_max                       0\n",
       "hist_month_lag_min                       0\n",
       "hist_month_lag_mean                      0\n",
       "hist_month_lag_var                       0\n",
       "hist_month_diff_mean                     0\n",
       "hist_authorized_flag_sum                 0\n",
       "hist_authorized_flag_mean                0\n",
       "                                        ..\n",
       "new_hist_month_lag_max                   0\n",
       "new_hist_month_lag_min                   0\n",
       "new_hist_month_lag_mean                  0\n",
       "new_hist_month_lag_var                   0\n",
       "new_hist_month_diff_mean                 0\n",
       "new_hist_weekend_sum                     0\n",
       "new_hist_weekend_mean                    0\n",
       "new_hist_category_1_sum                  0\n",
       "new_hist_category_1_mean                 0\n",
       "new_hist_card_id_size                    0\n",
       "new_hist_hour_nunique                    0\n",
       "new_hist_weekofyear_nunique              0\n",
       "new_hist_dayofweek_nunique               0\n",
       "new_hist_year_nunique                    0\n",
       "new_hist_subsector_id_nunique            0\n",
       "new_hist_merchant_id_nunique             0\n",
       "new_hist_merchant_category_id_nunique    0\n",
       "new_hist_category_2_mean_mean            0\n",
       "new_hist_category_3_mean_mean            0\n",
       "new_hist_purchase_date_diff              0\n",
       "new_hist_purchase_date_average           0\n",
       "new_hist_purchase_date_uptonow           0\n",
       "dayofweek                                1\n",
       "weekofyear                               1\n",
       "month                                    1\n",
       "elapsed_time                             1\n",
       "hist_first_buy                           1\n",
       "new_hist_first_buy                       0\n",
       "card_id_total                            0\n",
       "purchase_amount_total                    0\n",
       "Length: 83, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_X[test_X['weekofyear'].isna()]\n",
    "\n",
    "# test_X['weekofyear'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <th>hist_hour_nunique</th>\n",
       "      <th>hist_weekofyear_nunique</th>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <th>hist_year_nunique</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_merchant_id_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_date_uptonow</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>hist_first_buy</th>\n",
       "      <th>new_hist_first_buy</th>\n",
       "      <th>card_id_total</th>\n",
       "      <th>purchase_amount_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.024823</td>\n",
       "      <td>325.275599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>745.117156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.806745</td>\n",
       "      <td>100.484025</td>\n",
       "      <td>-19.767628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_1  feature_2  feature_3  hist_month_nunique  hist_hour_nunique  \\\n",
       "11578   0.013145   0.008752   0.011428                  11                 10   \n",
       "\n",
       "       hist_weekofyear_nunique  hist_dayofweek_nunique  hist_year_nunique  \\\n",
       "11578                       28                       7                  2   \n",
       "\n",
       "       hist_subsector_id_nunique  hist_merchant_id_nunique  \\\n",
       "11578                          2                         2   \n",
       "\n",
       "               ...            new_hist_purchase_date_average  \\\n",
       "11578          ...                                  5.024823   \n",
       "\n",
       "       new_hist_purchase_date_uptonow  dayofweek  weekofyear  month  \\\n",
       "11578                      325.275599        NaN         0.0    NaN   \n",
       "\n",
       "       elapsed_time  hist_first_buy  new_hist_first_buy  card_id_total  \\\n",
       "11578    745.117156             NaN          380.806745     100.484025   \n",
       "\n",
       "       purchase_amount_total  \n",
       "11578             -19.767628  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[test_X['dayofweek'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 5], [4, 5, 5]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1, 2, 3], [4, 5, 6]]\n",
    "for h in a:\n",
    "    h[2] = 5\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter {'lasso__alpha': 0.01, 'poly__degree': 2}\n",
      "3.8503312239493623\n",
      "CPU times: user 24min 50s, sys: 9min 27s, total: 34min 17s\n",
      "Wall time: 38min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = [{\"poly__degree\":[2], \"lasso__alpha\": [0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "poly_model = Pipeline([('poly', PolynomialFeatures(degree=3))\n",
    "             ,('lasso', Lasso(normalize=True))])\n",
    "\n",
    "\n",
    "grid = GridSearchCV(poly_model, cv=5, param_grid=params, scoring='neg_mean_squared_error')\n",
    "grid.fit(train_X, train_y)\n",
    "\n",
    "print('best parameter', grid.best_params_)\n",
    "print(np.mean(np.sqrt(-cross_val_score(grid.best_estimator_, train_X, train_y, cv=5, scoring='neg_mean_squared_error'))))\n",
    "\n",
    "predictions = grid.best_estimator_.predict(test_X)\n",
    "\n",
    "# predicted_X.to_csv('./output/svr.csv', index=False)\n",
    "\n",
    "sub_df = pd.DataFrame({\"card_id\":ids.values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"./output/poly_lasso.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # pca = PCA(0.9)\n",
    "# # train_X = pca.fit_transform(train_X)\n",
    "# # test_X = pca.transform(test_X)\n",
    "# params = [{\"alpha\":[0.01, 0.1, 10, 100]}]\n",
    "\n",
    "# ridge = Ridge(normalize=True)\n",
    "\n",
    "# grid = GridSearchCV(ridge, cv=5, param_grid=params, scoring='neg_mean_squared_error')\n",
    "# grid.fit(train_X, train_y)\n",
    "\n",
    "# print('best parameter', grid.best_params_)\n",
    "# print(np.mean(np.sqrt(-cross_val_score(grid.best_estimator_, train_X, train_y, cv=5, scoring='neg_mean_squared_error'))))\n",
    "\n",
    "# predictions = grid.best_estimator_.predict(test_X)\n",
    "\n",
    "# # predicted_X.to_csv('./output/svr.csv', index=False)\n",
    "\n",
    "# sub_df = pd.DataFrame({\"card_id\":ids.values})\n",
    "# sub_df[\"target\"] = predictions\n",
    "# sub_df.to_csv(\"./output/ridge.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # pca = PCA(0.9)\n",
    "# # train_X = pca.fit_transform(train_X)\n",
    "# # test_X = pca.transform(test_X)\n",
    "# params = [{\"alpha\":[0.01, 0.1, 10, 100]}]\n",
    "\n",
    "# lasso = Lasso(normalize=True)\n",
    "\n",
    "# grid = GridSearchCV(lasso, cv=5, param_grid=params, scoring='neg_mean_squared_error')\n",
    "# grid.fit(train_X, train_y)\n",
    "\n",
    "# print('best parameter', grid.best_params_)\n",
    "# print(np.mean(np.sqrt(-cross_val_score(grid.best_estimator_, train_X, train_y, cv=5, scoring='neg_mean_squared_error'))))\n",
    "\n",
    "# predictions = grid.best_estimator_.predict(test_X)\n",
    "\n",
    "# # predicted_X.to_csv('./output/svr.csv', index=False)\n",
    "\n",
    "# sub_df = pd.DataFrame({\"card_id\":ids.values})\n",
    "# sub_df[\"target\"] = predictions\n",
    "# sub_df.to_csv(\"./output/lasso.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # params = [{\"alpha\": [1e0, 0.1, 1e-2], \"gamma\": np.logspace(-2, 2, 3)}]\n",
    "\n",
    "# kernel_ridge = KernelRidge(kernel='rbf')\n",
    "\n",
    "# grid = GridSearchCV(kernel_ridge, cv=5, param_grid=params, scoring='neg_mean_squared_error')\n",
    "# grid.fit(train_X, train_y)\n",
    "\n",
    "# print('best parameter', grid.best_params_)\n",
    "# print(np.mean(np.sqrt(-cross_val_score(grid.best_estimator_, train_X, train_y, cv=5, scoring='neg_mean_squared_error'))))\n",
    "\n",
    "# predictions = grid.best_estimator_.predict(test_X)\n",
    "\n",
    "# # predicted_X.to_csv('./output/svr.csv', index=False)\n",
    "\n",
    "# sub_df = pd.DataFrame({\"card_id\":ids.values})\n",
    "# sub_df[\"target\"] = predictions\n",
    "# sub_df.to_csv(\"./output/kernel_ridge.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
