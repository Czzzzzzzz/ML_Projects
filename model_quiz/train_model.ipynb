{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_ks(label,score):\n",
    "    fpr,tpr,thresholds= roc_curve(label,score)\n",
    "    return max(tpr-fpr)\n",
    "    \n",
    "def cal_auc_ks(y_true, y_pred, name = None, save=False):\n",
    "    sample = name + \" Sample : %s\" % len(y_true)\n",
    "    auc = name + ' test_set auc : %0.3f' % roc_auc_score(y_true, y_pred)\n",
    "    ks = name + ' test_set ks  : %0.3f' % cal_ks(y_true,y_pred) \n",
    "    print (sample)\n",
    "    print (auc)\n",
    "    print (ks)\n",
    "    print ('----------------cal_auc_ks process successfully!----------------')\n",
    "    if save:\n",
    "        if name:\n",
    "            pass\n",
    "        else:\n",
    "            name = ''\n",
    "        with open(name + '_auc&ks.txt', 'a+') as f:\n",
    "            f.write(sample + '\\n' + auc + '\\n' + ks + '\\n' + '------------------------------------' + '\\n' )\n",
    "            print ('----------------cal_auc_ks save successfully!----------------')\n",
    "    return roc_auc_score(y_true, y_pred), cal_ks(y_true,y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dimensions_of_data(file_name):\n",
    "    max_dimension = -1\n",
    "    min_dimension = 1e6\n",
    "    with open(file_name, 'r') as f:    \n",
    "        lines = f.readlines()\n",
    "        for line in lines[1:2]:\n",
    "            data, label = line.split('\\t')\n",
    "            \n",
    "            for pair in data.split(' '):\n",
    "                index = int(pair.split(':')[0])\n",
    "                max_dimension = max(index, max_dimension)\n",
    "                min_dimension = min(index, min_dimension)\n",
    "                \n",
    "    return max_dimension, min_dimension\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#确定数据的维度\n",
    "\n",
    "train_dims, train_min_dims = dimensions_of_data('train.data')\n",
    "test_dims, test_min_dims = dimensions_of_data('test.data')\n",
    "dims = max(train_dims, test_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name, dims):\n",
    "    \n",
    "    with open(file_name, 'r') as f:    \n",
    "        lines = f.readlines()        \n",
    "        \n",
    "        rows, cols = len(lines) - 1, dims + 2\n",
    "        all_data = np.array([[np.nan for _ in range(cols)] for _ in range(rows)])\n",
    "\n",
    "        for idx, line in enumerate(lines[1:]):\n",
    "            data, label = line.split('\\t')\n",
    "            \n",
    "            all_data[idx, -1] = float(label)\n",
    "            \n",
    "            for pair in data.split(' '):\n",
    "                index = int(pair.split(':')[0])\n",
    "                val = pair.split(':')[1]\n",
    "                \n",
    "                all_data[idx, index] = val\n",
    "    \n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = read_data('train.data', dims)\n",
    "test = read_data('test.data', dims)\n",
    "feature_violin = pd.read_csv('feature_violin.txt', header = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用从lightgbm训练得到的feature重要性来做特征选择, 挑出重要性值大于50的特征\n",
    "\n",
    "# feature_importance = pd.read_csv('feature_importance_lgb.txt', header=-1)\n",
    "# feature_importance_threshold = 50\n",
    "\n",
    "# feature_importance_index = feature_importance[feature_importance.iloc[:, 1] > feature_importance_threshold].iloc[:, 0]\n",
    "\n",
    "# def feature_select(data, idx):\n",
    "    \n",
    "#     X = data.iloc[:, :-1]\n",
    "#     y = data.iloc[:, -1]\n",
    "    \n",
    "#     y_name = data.columns[-1]\n",
    "    \n",
    "#     X = X[idx]\n",
    "#     X[y_name] = y\n",
    "\n",
    "#     return X\n",
    "\n",
    "# train = feature_select(train, feature_importance_index)\n",
    "# test = feature_select(test, feature_importance_index)\n",
    "\n",
    "# 在使用lightgbm训练得到的feature重要性来做特征选择后, 用violin plot进一步筛选重要特征\n",
    "train = feature_select(train, feature_violin[0])\n",
    "test = feature_select(test, feature_violin[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 填充缺失值，对“猜测”的连续变量填充均值，对离散变量填充众数\n",
    "\n",
    "uniq_counts = np.array([train.iloc[:, c].unique().shape[0] for c in range(train.shape[1])])\n",
    "categorical_cols = train.columns[uniq_counts < 10]\n",
    "numerical_cols = train.columns[uniq_counts >= 10]\n",
    "\n",
    "\n",
    "for cat_col in categorical_cols:\n",
    "    mode = train[cat_col].mode()[0]\n",
    "    train[cat_col].fillna(mode, inplace=True)\n",
    "    test[cat_col].fillna(mode, inplace=True)\n",
    "    \n",
    "for num_col in numerical_cols:\n",
    "    mean = train[num_col].mean()\n",
    "    train[num_col].fillna(mean, inplace=True)    \n",
    "    test[num_col].fillna(mean, inplace=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train.iloc[:, :-1]\n",
    "train_y = train.iloc[:, -1].astype('int')\n",
    "\n",
    "test_X = test.iloc[:, :-1]\n",
    "test_y = test.iloc[:, -1].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========svc=============\n",
      "results Sample : 2999\n",
      "results test_set auc : 0.679\n",
      "results test_set ks  : 0.358\n",
      "----------------cal_auc_ks process successfully!----------------\n",
      "confusion matrix: [[1529  721]\n",
      " [ 241  508]]\n",
      "f1 score: 0.5136501516683519\n",
      "=========lr=============\n",
      "results Sample : 2999\n",
      "results test_set auc : 0.689\n",
      "results test_set ks  : 0.377\n",
      "----------------cal_auc_ks process successfully!----------------\n",
      "confusion matrix: [[1587  785]\n",
      " [ 183  444]]\n",
      "f1 score: 0.478448275862069\n",
      "=========lgb_clf=============\n",
      "results Sample : 2999\n",
      "results test_set auc : 0.716\n",
      "results test_set ks  : 0.433\n",
      "----------------cal_auc_ks process successfully!----------------\n",
      "confusion matrix: [[1594  719]\n",
      " [ 176  510]]\n",
      "f1 score: 0.5326370757180158\n",
      "=========ensembel_model=============\n",
      "results Sample : 2999\n",
      "results test_set auc : 0.731\n",
      "results test_set ks  : 0.461\n",
      "----------------cal_auc_ks process successfully!----------------\n",
      "confusion matrix: [[1626  738]\n",
      " [ 144  491]]\n",
      "f1 score: 0.5268240343347639\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto', kernel='poly', C=0.01, probability=True)\n",
    "lr = LogisticRegression(C=0.05, penalty='l1')\n",
    "lgb_clf = lgb.LGBMClassifier(learning_rate=0.01, n_estimators=500, silent=True)\n",
    "\n",
    "ensembel_model = VotingClassifier(estimators=[('svc', svc), ('lr', lr), ('lgb_clf', lgb_clf)], voting='soft', weights=[1, 1, 1.5])\n",
    "\n",
    "for cls, name in zip([svc, lr, lgb_clf, ensembel_model], ['svc', 'lr', 'lgb_clf', 'ensembel_model']):\n",
    "    cls.fit(train_X, train_y)\n",
    "    predictions = cls.predict(test_X)\n",
    "    \n",
    "    print('=========' + name + '=============')\n",
    "    cal_auc_ks(predictions, test_y, name='results')\n",
    "    print('confusion matrix:', confusion_matrix(predictions, test_y))\n",
    "    print('f1 score:', f1_score(predictions, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(clf, filename='model.pkl'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "        \n",
    "save_model(ensembel_model, 'model.pkl')\n",
    "\n",
    "# # and later you can load it\n",
    "# with open('filename.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
