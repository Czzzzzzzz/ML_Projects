{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class and Multi-Label classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Frogs_MFCCs.csv')\n",
    "\n",
    "data_all = data.iloc[:, :-4]\n",
    "label_all = data.iloc[:, -4:-1]\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(data_all, label_all, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7195, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_class_label_hamming_loss(ground_truth, predictions):\n",
    "    if type(ground_truth) == pd.DataFrame:\n",
    "        ground_truth = ground_truth.values\n",
    "    if type(predictions) == pd.DataFrame:\n",
    "        predictions = predictions.values\n",
    "        \n",
    "    res = np.sum(np.not_equal(ground_truth, predictions)) / ground_truth.size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty 0.000, gamma 0.100\n",
      "penalty 0.000, gamma 0.200\n",
      "penalty 0.000, gamma 0.300\n",
      "penalty 0.000, gamma 0.400\n",
      "penalty 0.000, gamma 0.500\n",
      "penalty 0.000, gamma 0.600\n",
      "penalty 0.000, gamma 0.700\n",
      "penalty 0.000, gamma 0.800\n",
      "penalty 0.000, gamma 0.900\n",
      "penalty 0.000, gamma 0.100\n",
      "penalty 0.000, gamma 0.200\n",
      "penalty 0.000, gamma 0.300\n",
      "penalty 0.000, gamma 0.400\n",
      "penalty 0.000, gamma 0.500\n",
      "penalty 0.000, gamma 0.600\n",
      "penalty 0.000, gamma 0.700\n",
      "penalty 0.000, gamma 0.800\n",
      "penalty 0.000, gamma 0.900\n",
      "penalty 0.002, gamma 0.100\n",
      "penalty 0.002, gamma 0.200\n",
      "penalty 0.002, gamma 0.300\n",
      "penalty 0.002, gamma 0.400\n",
      "penalty 0.002, gamma 0.500\n",
      "penalty 0.002, gamma 0.600\n",
      "penalty 0.002, gamma 0.700\n",
      "penalty 0.002, gamma 0.800\n",
      "penalty 0.002, gamma 0.900\n",
      "penalty 0.010, gamma 0.100\n",
      "penalty 0.010, gamma 0.200\n",
      "penalty 0.010, gamma 0.300\n",
      "penalty 0.010, gamma 0.400\n",
      "penalty 0.010, gamma 0.500\n",
      "penalty 0.010, gamma 0.600\n",
      "penalty 0.010, gamma 0.700\n",
      "penalty 0.010, gamma 0.800\n",
      "penalty 0.010, gamma 0.900\n",
      "penalty 0.046, gamma 0.100\n",
      "penalty 0.046, gamma 0.200\n",
      "penalty 0.046, gamma 0.300\n",
      "penalty 0.046, gamma 0.400\n",
      "penalty 0.046, gamma 0.500\n",
      "penalty 0.046, gamma 0.600\n",
      "penalty 0.046, gamma 0.700\n",
      "penalty 0.046, gamma 0.800\n",
      "penalty 0.046, gamma 0.900\n",
      "penalty 0.215, gamma 0.100\n",
      "penalty 0.215, gamma 0.200\n",
      "penalty 0.215, gamma 0.300\n",
      "penalty 0.215, gamma 0.400\n",
      "penalty 0.215, gamma 0.500\n",
      "penalty 0.215, gamma 0.600\n",
      "penalty 0.215, gamma 0.700\n",
      "penalty 0.215, gamma 0.800\n",
      "penalty 0.215, gamma 0.900\n",
      "penalty 1.000, gamma 0.100\n",
      "penalty 1.000, gamma 0.200\n",
      "penalty 1.000, gamma 0.300\n",
      "penalty 1.000, gamma 0.400\n",
      "penalty 1.000, gamma 0.500\n",
      "penalty 1.000, gamma 0.600\n",
      "penalty 1.000, gamma 0.700\n",
      "penalty 1.000, gamma 0.800\n",
      "penalty 1.000, gamma 0.900\n",
      "penalty 4.642, gamma 0.100\n",
      "penalty 4.642, gamma 0.200\n",
      "penalty 4.642, gamma 0.300\n",
      "penalty 4.642, gamma 0.400\n",
      "penalty 4.642, gamma 0.500\n",
      "penalty 4.642, gamma 0.600\n",
      "penalty 4.642, gamma 0.700\n",
      "penalty 4.642, gamma 0.800\n",
      "penalty 4.642, gamma 0.900\n",
      "penalty 21.544, gamma 0.100\n",
      "penalty 21.544, gamma 0.200\n",
      "penalty 21.544, gamma 0.300\n",
      "penalty 21.544, gamma 0.400\n",
      "penalty 21.544, gamma 0.500\n",
      "penalty 21.544, gamma 0.600\n",
      "penalty 21.544, gamma 0.700\n",
      "penalty 21.544, gamma 0.800\n",
      "penalty 21.544, gamma 0.900\n",
      "penalty 100.000, gamma 0.100\n",
      "penalty 100.000, gamma 0.200\n",
      "penalty 100.000, gamma 0.300\n",
      "penalty 100.000, gamma 0.400\n",
      "penalty 100.000, gamma 0.500\n",
      "penalty 100.000, gamma 0.600\n",
      "penalty 100.000, gamma 0.700\n",
      "penalty 100.000, gamma 0.800\n",
      "penalty 100.000, gamma 0.900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44308066942261776,\n",
       " -0.44288199375177506,\n",
       " -0.44089589447442334,\n",
       " -0.34491884670811113,\n",
       " -0.26694633784594024,\n",
       " -0.22028201163390029,\n",
       " -0.20347110458939482,\n",
       " -0.19354126563371096,\n",
       " -0.18778401022436811,\n",
       " -0.1839448757192296,\n",
       " -0.18003828878580372,\n",
       " -0.20995758254704575,\n",
       " -0.17467943660786603,\n",
       " -0.12748430054593077,\n",
       " -0.10643177969221707,\n",
       " -0.098818990817002753,\n",
       " -0.092927882440804896,\n",
       " -0.087036642578392082,\n",
       " -0.082074747283494801,\n",
       " -0.078302276289353823,\n",
       " -0.10371777272870712,\n",
       " -0.077839181840175881,\n",
       " -0.067779697476516562,\n",
       " -0.059704340096984235,\n",
       " -0.055335316145455303,\n",
       " -0.051760600418652117,\n",
       " -0.048914449809082015,\n",
       " -0.044942382740593478,\n",
       " -0.041102722290595049,\n",
       " -0.061821531130676254,\n",
       " -0.046135620141584358,\n",
       " -0.036337924831960619,\n",
       " -0.031901053993499316,\n",
       " -0.028459007857616202,\n",
       " -0.022964461905813794,\n",
       " -0.019985773191538596,\n",
       " -0.018596884302649708,\n",
       " -0.01707453690555082,\n",
       " -0.036734092797711088,\n",
       " -0.024157041875729746,\n",
       " -0.018332597010529417,\n",
       " -0.015089489517918938,\n",
       " -0.013832349816445244,\n",
       " -0.013104179157857087,\n",
       " -0.012772833896094331,\n",
       " -0.011912651077661016,\n",
       " -0.011383024603700548,\n",
       " -0.021509566937002324,\n",
       " -0.014957608844288765,\n",
       " -0.013103653212997149,\n",
       " -0.01191225661901606,\n",
       " -0.010721254483679931,\n",
       " -0.010456178274269727,\n",
       " -0.010059221391229344,\n",
       " -0.0095295949172688743,\n",
       " -0.0095295949172688708,\n",
       " -0.014758275742371169,\n",
       " -0.01224386485320879,\n",
       " -0.010786866104957556,\n",
       " -0.010323903141994592,\n",
       " -0.010191496523504474,\n",
       " -0.010125490443581894,\n",
       " -0.0098609401790316301,\n",
       " -0.0091329010066584608,\n",
       " -0.0088020816897556465]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalties = np.logspace(-4, 2, 10)\n",
    "gammas = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "hamming_loss_scorer = make_scorer(multi_class_label_hamming_loss, greater_is_better=False)\n",
    "\n",
    "cvs = []\n",
    "for penalty in penalties:\n",
    "    for gamma in gammas:\n",
    "        print('penalty %.3f, gamma %.3f' % (penalty, gamma))\n",
    "        svc = SVC(C=penalty, gamma=gamma)\n",
    "        multi_svc = MultiOutputClassifier(svc)\n",
    "        cvs.append(np.mean(cross_val_score(multi_svc, train_data, train_label, scoring=hamming_loss_scorer ,cv=10)))\n",
    "        \n",
    "\n",
    "cvs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22222222222222221"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame([[2, 1, 1], [1, 2, 2], [0, 1, 1]])\n",
    "b = pd.DataFrame([[2, 0, 1], [1, 1, 2], [0, 1, 1]])\n",
    "# hamming_loss(a, b)\n",
    "\n",
    "c = multi_class_label_hamming_loss(a, b)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
